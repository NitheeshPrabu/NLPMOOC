{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "70894730-f4d6-4a45-8e3d-1dc5c282bca3"
    }
   },
   "source": [
    "<h1 align=\"center\">Parsing with Context Free Grammars(CFG) and PCFG (Probabilistic CFG)</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import io\n",
    "import IPython\n",
    "import PIL.Image\n",
    "from nltk import Tree\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from nltk.draw import TreeWidget\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is assumed that NLTK is already installed on the notebook.\n",
    "- We need to install `punkt` tokeniser as well\n",
    "- the code snippet `nltk.download('punkt')` should install the tokeniser\n",
    "- If it does not work, type `nltk.download()`, a gui based window will appear.\n",
    "    - Click on the tab `Model`\n",
    "    - Selcect the option `punkt`\n",
    "    - click on `Download`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/amrith/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.download('punkt')\n",
    "except:\n",
    "    nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "85e969e1-b3ef-4de3-977e-d9afc42b7011"
    }
   },
   "source": [
    "## Question 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 773-702-7034 Carl Sandburg Middle School , W. Hawley Street , LOCATED IN THE GYM ,Mundelein, IL , us , 60060\n",
      "2 Harold Washington Library Center , 400 S. State Street , Cindy Pritzker Auditorium , Chicago , IL , us , 60605\n",
      "(S\n",
      "  (NM NAME (NM NAME (NM NAME (NM NAME))))\n",
      "  (ADD1 (N NUM) (DIR S.) (ST STREET1 (ST STREET1)))\n",
      "  (ADD2 (ST1 STREET2 (ST1 STREET2 (ST1 STREET2))))\n",
      "  (CT CITY)\n",
      "  (STATE STATE)\n",
      "  (COUNTRY us)\n",
      "  (Z ZIP))\n",
      "(S\n",
      "  (NM NAME (NM NAME (NM NAME (NM NAME NUM))))\n",
      "  (ADD1 (DIR S.) (ST STREET1 (ST STREET1)))\n",
      "  (ADD2 (ST1 STREET2 (ST1 STREET2 (ST1 STREET2))))\n",
      "  (CT CITY)\n",
      "  (STATE STATE)\n",
      "  (COUNTRY us)\n",
      "  (Z ZIP))\n",
      "1 Dive Chicago , Slip K-27 , Burnham Harbor , Chicago , IL , us , 60660\n",
      "1 Kettle Moraine State Forest Southern Unit , Forest Headquarters , S91 W39091 Highway 59 , Eagle , WI , us , 53119\n",
      "1 Jack Benny Park , Downtown Waukegan , Corner of Clayton and Genesee Streets , Waukegan , IL , us , 60085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input addresses\n",
    "f = ['773-702-7034 Carl Sandburg Middle School , W. Hawley Street , LOCATED IN THE GYM ,Mundelein, IL , us , 60060', \n",
    "'Harold Washington Library Center , 400 S. State Street , Cindy Pritzker Auditorium , Chicago , IL , us , 60605',\n",
    "'Dive Chicago , Slip K-27 , Burnham Harbor , Chicago , IL , us , 60660',\n",
    "'Kettle Moraine State Forest Southern Unit , Forest Headquarters , S91 W39091 Highway 59 , Eagle , WI , us , 53119',\n",
    "'Jack Benny Park , Downtown Waukegan , Corner of Clayton and Genesee Streets , Waukegan , IL , us , 60085']\n",
    "\n",
    "\n",
    "# Grammar G1\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S ->  N NM ADD1 ADD2 CT STATE COUNTRY Z |NM ADD1 ADD2 CT STATE COUNTRY Z| NM ADD1 CT STATE COUNTRY Z\n",
    "NM -> 'NAME' NM | 'NAME' 'NUM' NM | 'NAME' 'NUM' | 'NAME'\n",
    "ADD1 -> N DIR ST | ST | N DIR | N DIR AVE | AVE | N AVE | N ST |AVE N| ST N | AVE DIR |ST DIR | AVE DIR AVE| AVE DIR AVE |ST DIR ST |AVE N AVE | ST N ST | N DIR N SS AVE |N DIR N SS ST | N DIR N SS AVE |N DIR N SS ST |  DIR AVE |DIR ST\n",
    "ADD2 -> FL ST1 | FL | SUI | SUI FL | SUI FL ST1 | FL SUI | DIR ST1 |N DIR ST1 | ST1 | N DIR | N ST1 | N SS ST1 | ST1 N |ST1 DIR ST1 | 'NUM'\n",
    "N -> 'NUM' \n",
    "CT -> 'CITY' | 'CITY' 'CITY' | 'CITY' 'CITY' 'CITY'\n",
    "STATE -> 'STATE' | STATE 'STATE'\n",
    "Z -> 'ZIP'\n",
    "COUNTRY -> 'COUNTRY'| COUNTRY 'COUNTRY'|'us'|'US'\n",
    "DIR -> 'N.' | 'S.' | 'W.'|'E.'|'North'|'South'|'West'|'East'|'N'|'S'|'E'|'W'|'w.'|'s.'|'n.'|'e.'\n",
    "ST -> 'STREET1' ST | 'STREET1' 'NUM' | 'STREET1' 'NUM' ST| 'STREET1'\n",
    "AVE -> 'AVENUE' AVE | 'AVENUE'\n",
    "ST1 -> 'STREET2' ST1 | 'STREET2'\n",
    "SUI -> SU N\n",
    "FL -> N SS F | N F | OTH F | F N SS\n",
    "OTH -> 'Top' | 'Main'\n",
    "F -> 'FLOOR'\n",
    "SU -> 'SUITE'\n",
    "SS -> 'SUP'\n",
    "\"\"\")\n",
    "\n",
    "pattern = [(r'^(?!(?:^[0-9][0-9][0-9][0-9][0-9]+$)$)\\d+','NUM'),\n",
    "           (r'^(?!(?:^[0-9][0-9][0-9][0-9][0-9]+$)|(\\(|\\)|us|US|N\\.|W\\.|E\\.|S\\.|N|W|E|S|n\\.|w.|e\\.|s\\.|Ave|Ave\\.|ave|avenue|Avenue|AVENUE|ave\\.|Suite|suite|SUITE|Floor|Fl.|Fl|floor|nd|th)$).*','STREET1'),\n",
    "           (r'(Suite|suite|SUITE)','SUITE'),(r'(nd|th)','SUP'),(r'(floor|Fl.|Fl|Floor)','FLOOR'),(',','COM'),\n",
    "           (r'\\(|\\)','BRAC'),(r'Ave|Ave.|ave|avenue|Avenue|AVENUE|ave.','AVENUE'),(r'^[0-9][0-9][0-9][0-9][0-9]+$','ZIP')]\n",
    "\n",
    "count = 0\n",
    "total_count = 0\n",
    "tagger = nltk.RegexpTagger(pattern)\n",
    "parser = nltk.ChartParser(grammar1)\n",
    "\n",
    "for line in f:\n",
    "    c=0\n",
    "    adr1 = line\n",
    "    t=[]\n",
    "    f=0\n",
    "    p=0\n",
    "    start=0\n",
    "    end=0\n",
    "    x = None\n",
    "    \n",
    "    for (y,x) in (tagger.tag(nltk.word_tokenize(adr1))):\n",
    "        \n",
    "        if y == ',':\n",
    "            x = 'COM'\n",
    "\n",
    "        if x is not None and x != 'COM' and f==0:\n",
    "            if x == 'STREET1' :\n",
    "\n",
    "                t.append('NAME')\n",
    "            else:\n",
    "                t.append(x)\n",
    "        elif x is not None and x != 'COM' and f==1:\n",
    "            t.append(x)\n",
    "        elif x is not None and x != 'COM'  and f==2:\n",
    "            if x == 'STREET1' :\n",
    "                x='STREET2'\n",
    "            t.append(x)\n",
    "        elif x is not None and x != 'COM'  and f==3:\n",
    "            if x == 'STREET1' :\n",
    "                x='CITY'\n",
    "            t.append(x)\n",
    "        elif x is not None and x != 'COM' and f==4:\n",
    "            if x == 'STREET1' :\n",
    "                x='STATE'\n",
    "            t.append(x)\n",
    "        elif x is not None and x != 'COM' and  f==5:\n",
    "            if x == 'STREET1' :\n",
    "                x='COUNTRY'\n",
    "            t.append(x)     \n",
    "        elif x is not None and x != 'COM'  and f==6:\n",
    "            t.append(x)\n",
    "        elif x == 'COM' :\n",
    "            f+=1\n",
    "        elif x is None  :\n",
    "            t.append(y)\n",
    "    \n",
    "    num_of_parse = len(list(parser.parse(t)))\n",
    "\n",
    "    print num_of_parse,adr1\n",
    "    for tree in parser.parse(t):\n",
    "        if num_of_parse > 1:\n",
    "            print tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NM (X7 NAME) (NM (X7 NAME) (NM NAME)))\n",
      "  (X1\n",
      "    (ADD1 (ST STREET1) (STREET1 STREET1))\n",
      "    (X2\n",
      "      (ADD2\n",
      "        (STREET2 STREET2)\n",
      "        (ST1\n",
      "          (STREET2 STREET2)\n",
      "          (ST1\n",
      "            (STREET2 STREET2)\n",
      "            (ST1\n",
      "              (STREET2 STREET2)\n",
      "              (ST1 (STREET2 STREET2) (ST1 STREET2))))))\n",
      "      (X3\n",
      "        (CT CITY)\n",
      "        (X4 (STATE IL) (X5 (COUNTRY us) (Z ZIP))))))) (p=2.09019e-06)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#an example address string\n",
    "adr1 = \"Jack Benny Park , Downtown Waukegan , Corner of Clayton and Genesee Streets , Waukegan , IL , us , 60085\"\n",
    "\n",
    "#specify the grammer with each production with the probabilities\n",
    "grammar1 = \\\n",
    "    nltk.PCFG.fromstring(\"\"\"\n",
    "S -> NM X1 [0.6] | NM X6 [0.4]\n",
    "X6 -> ADD1 X3 [1.0]\n",
    "X1 -> ADD1 X2 [1.0]\n",
    "X2 -> ADD2 X3 [1.0]\n",
    "X3 -> CT X4 [1.0]\n",
    "X4 -> STATE X5 [1.0]\n",
    "X5 -> COUNTRY Z [1.0]\n",
    "NM -> X7 NM [0.4] | X7 X8 [0.1]  | 'NAME' [0.5] \n",
    "X7 -> 'NAME' [1.0]\n",
    "X8 -> N NM [1.0]\n",
    "ADD1 -> X9 ST [0.3] | ST STREET1 [0.25] | 'STREET1' [0.1] | N DIR [0.1] | X9 AVE [0.05] | AVENUE AVE [0.1]| 'AVENUE' [0.06]| N ST [0.04]\n",
    "X9 -> N DIR [1.0]\n",
    "ADD2 -> FL ST1 [0.1]| X11 F [0.033]| N F [0.067]| OTH F [0.1]| F X11 [0.1]| SU N [0.1]| SUI FL [0.1]| SUI X13 [0.05]| FL SUI [0.05]| DIR ST1 [0.02]| N X14 [0.04]| STREET2 ST1 [0.04]| 'STREET2' [0.01]| N DIR [0.04]| N ST1 [0.05]| N X15 [0.01]| ST1 N [0.02]|ST1 X16 [0.02]| 'NUM' [0.05]\n",
    "X16 -> DIR ST1 [1.0]\n",
    "X15 -> SS ST1 [1.0]\n",
    "X14 -> DIR ST1 [1.0]\n",
    "X13 -> FL ST1 [1.0]\n",
    "N -> 'NUM' [1.0]\n",
    "CITY -> 'CITY' [1.0]\n",
    "CT -> 'CITY' [0.4] | CITY CITY [0.6]\n",
    "STATE -> 'IL' [1.0]\n",
    "Z -> 'ZIP' [1.0]\n",
    "COUNTRY -> 'us' [0.7] | 'US' [0.3]\n",
    "DIR -> 'N.' [0.1]| 'S.'[0.1] | 'W.' [0.1] |'E.' [0.1] |'North' [0.05] |'South' [0.05] |'West' [0.05]|'East' [0.05]|'N' [0.05] |'S' [0.05]|'E' [0.05] |'W' [0.05]|'w.' [0.05]|'s.' [0.05] |'n.' [0.05] |'e.' [0.05]\n",
    "STREET1 -> 'STREET1' [1.0]\n",
    "ST -> STREET1 ST [0.3] | STREET1 N [0.2]| STREET1 X10 [0.2]| 'STREET1' [0.3]\n",
    "X10 -> N ST [1.0]\n",
    "AVE -> AVENUE AVE [0.6] | 'AVENUE' [0.4]\n",
    "AVENUE -> 'AVENUE' [1.0]\n",
    "STREET2 ->\t'STREET2' [1.0]\n",
    "ST1 -> STREET2 ST1 [0.6] | 'STREET2' [0.4]\n",
    "SUI -> SU N [1.0]\n",
    "FL -> X11 F [0.3] | N F [0.2] | OTH F [0.2] | F X11 [0.3]\n",
    "X11 -> N SS [1.0]\n",
    "OTH -> 'Top' [0.5] | 'Main' [0.5]\n",
    "F -> 'FLOOR' [1.0]\n",
    "SU -> 'SUITE' [1.0]\n",
    "SS -> 'SUP' [1.0]\n",
    "\"\"\")\n",
    "\n",
    "pattern = [(r'^(?!(?:^6[0-9]{4,4}$)$)\\d+','NUM'),(r'^(?!(?:^6[0-9]{4,4}$)|(\\(|\\)|IL|us|US|N\\.|W\\.|E\\.|S\\.|N|W|E|S|n\\.|w\\.|e\\.|s\\.|Ave|Ave\\.|ave|avenue|Avenue|AVENUE|ave\\.|West|North|East|,|South|Suite|suite|SUITE|Floor|Fl.|Fl|floor|nd|th)$).*','STREET1'),(r'(Suite|suite|SUITE)','SUITE'),(r'(nd|th)','SUP'),(r'(floor|Fl.|Fl|Floor)','FLOOR'),(r',','COM'),(r'\\(|\\)','BRAC'),(r'Ave|Ave.|ave|avenue|Avenue|AVENUE|ave.','AVENUE'),(r'^6[0-9]{4,4}$','ZIP')]\n",
    "tagger = nltk.RegexpTagger(pattern)\n",
    "    \n",
    "t = []\n",
    "f = 0\n",
    "p = 0\n",
    "start = 0\n",
    "end = 0\n",
    "for (y, x) in tagger.tag(nltk.word_tokenize(adr1)):\n",
    "    if x is not None and x != 'COM' and x != 'BRAC' and f == 0:\n",
    "        if x == 'STREET1':\n",
    "            x = 'NAME'\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 1:\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 2:\n",
    "        if x == 'STREET1':\n",
    "            x = 'STREET2'\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 3:\n",
    "        if x == 'STREET1':\n",
    "            x = 'CITY'\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 6:\n",
    "        t.append(x)\n",
    "    elif x == 'COM':\n",
    "        f += 1\n",
    "    elif x == None:\n",
    "        t.append(y)\n",
    "            \n",
    "tokens = t\n",
    "grammar = grammar1\n",
    "\n",
    "\n",
    "    \n",
    "#creating table\n",
    "size = len(tokens)\n",
    "table = [ [[] for i in range(size)] for i in range(size) ]\n",
    "\n",
    "viterbi_parser = nltk.ViterbiParser(grammar) \n",
    "\n",
    "for tree in viterbi_parser.parse(tokens):\n",
    "    print tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (NP (DT a) (NN boy)) (PP (IN with) (NP (DT a) (NN telescope)))) (VP (VBD saw) (NP (DT a) (NN girl))))\n",
      "0.000658161979833\n",
      "PP # 3 # 5 # 0.380952380952 # 0.0552856063059\n",
      "NP # 1 # 5 # 0.0414642047294 # 0.507936507937\n",
      "NN # 2 # 5 # 0.0 # 0.580498866214\n",
      "DT # 1 # 4 # 0.0 # 0.290249433106\n",
      "NP # 7 # 8 # 0.380952380952 # 0.0552856063059\n",
      "NP # 4 # 5 # 0.380952380952 # 0.0552856063059\n",
      "S # 1 # 8 # 0.0210611833546 # 1\n",
      "DT # 7 # 7 # 0.666666666667 # 0.0315917750319\n",
      "NP # 1 # 2 # 0.380952380952 # 0.0552856063059\n",
      "VP # 6 # 8 # 0.507936507937 # 0.0414642047294\n",
      "VBD # 6 # 6 # 1.0 # 0.0210611833546\n",
      "VP # 3 # 8 # 0.0 # 0.380952380952\n",
      "IN # 3 # 3 # 1.0 # 0.0210611833546\n",
      "DT # 4 # 4 # 0.666666666667 # 0.0315917750319\n",
      "VBD # 3 # 6 # 0.0 # 0.193499622071\n",
      "S # 4 # 8 # 0.193499622071 # 0.0\n",
      "DT # 1 # 1 # 0.666666666667 # 0.0315917750319\n",
      "{('DT', 'the'): 0.333333333333, ('IN', 'with'): 1.0, ('DT', 'a'): 0.666666666667, ('NN', 'boy'): 0.333333333333, ('VBD', 'saw'): 1.0, ('NN', 'girl'): 0.333333333333, ('NN', 'telescope'): 0.333333333333}\n",
      "{('PP', 'IN', 'NP'): 1.0, ('VP', 'VP', 'PP'): 0.333333333333, ('VP', 'VBD', 'NP'): 0.666666666667, ('NP', 'NP', 'PP'): 0.142857142857, ('NP', 'DT', 'NN'): 0.857142857143, ('S', 'NP', 'VP'): 1.0}\n",
      "(S (NP (NP (DT a) (NN boy)) (PP (IN with) (NP (DT a) (NN telescope)))) (VP (VBD saw) (NP (DT a) (NN girl))))\n",
      "0.000658161979833\n"
     ]
    }
   ],
   "source": [
    "from parser import *\n",
    "\n",
    "#sentence\n",
    "s = 'a boy with a telescope saw a girl'\n",
    "parser = PCFGParser('model.bin') \n",
    "parser.writeOutResult(s, '2.out')\n",
    "result, value = parser.parse(s)\n",
    "# Grammar Productions\n",
    "print parser.unaries\n",
    "print parser.binaries\n",
    "\n",
    "print result\n",
    "print value"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
